{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Exemplos YOLO V11](https://docs.ultralytics.com/pt/modes/train/#usage-examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.153 available  Update with 'pip install -U ultralytics'\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'\u001b[31m\u001b[1msomething\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '--f=c:\\\\Users\\\\Cristiano\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v31112d52c023b2ad34d3e40b2d71d10b979edf34b.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of frozenset({'detect', 'segment', 'classify', 'pose', 'obb'})\n                MODE (required) is one of frozenset({'predict', 'train', 'export', 'track', 'benchmark', 'val'})\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n\n    5. Ultralytics solutions usage\n        yolo solutions count or in ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video.mp4\"\n\n    6. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n        yolo solutions help\n\n    Docs: https://docs.ultralytics.com\n    Solutions: https://docs.ultralytics.com/solutions/\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n     (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[2], line 14\u001b[0m\n    results = model.train(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\Cristiano\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:787\u001b[0m in \u001b[0;35mtrain\u001b[0m\n    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\Cristiano\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:105\u001b[0m in \u001b[0;35m__init__\u001b[0m\n    self.args = get_cfg(cfg, overrides)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\Cristiano\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py:308\u001b[0m in \u001b[0;35mget_cfg\u001b[0m\n    check_dict_alignment(cfg, overrides)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32mc:\\Users\\Cristiano\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py:498\u001b[1;36m in \u001b[1;35mcheck_dict_alignment\u001b[1;36m\n\u001b[1;33m    raise SyntaxError(string + CLI_HELP_MSG) from e\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>\u001b[1;36m\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '\u001b[31m\u001b[1msomething\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '--f=c:\\\\Users\\\\Cristiano\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v31112d52c023b2ad34d3e40b2d71d10b979edf34b.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of frozenset({'detect', 'segment', 'classify', 'pose', 'obb'})\n                MODE (required) is one of frozenset({'predict', 'train', 'export', 'track', 'benchmark', 'val'})\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n\n    5. Ultralytics solutions usage\n        yolo solutions count or in ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video.mp4\"\n\n    6. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n        yolo solutions help\n\n    Docs: https://docs.ultralytics.com\n    Solutions: https://docs.ultralytics.com/solutions/\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n    \n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO, RTDETR\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# model = YOLO(\"yolo12s.yaml\")  # build a new model from YAML\n",
    "\n",
    "model = RTDETR('rtdetr-l.pt')  # load architecture only\n",
    "\n",
    "\n",
    "# Create a path to your custom dataset YAML\n",
    "data_yaml_path = \"./data.yaml\"\n",
    "\n",
    "# Train the model using your custom dataset\n",
    "results = model.train(\n",
    "    data=data_yaml_path,\n",
    "    epochs=450,\n",
    "    imgsz=640,\n",
    "    project=\"rtdetr-chessred\",  # project name for saving results\n",
    "    name=\"RTDETRLPretrained50AdamWCosLr\",         # experiment name\n",
    "    batch=16,                 # batch size (adjust based on your GPU memory)\n",
    "    device=0,                 # GPU device (0 for first GPU)\n",
    "    patience=50,              # early stopping patience\n",
    "    save=True,                # save checkpoints\n",
    "    optimizer=\"AdamW\",        # use AdamW optimizer\n",
    "    # pretrained=True,          # use pretrained weights\n",
    "    cos_lr=True,              # use cosine learning rate scheduler\n",
    "    visualize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
