{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import to_tensor, resize, hflip, vflip, rotate, normalize\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_joint_transforms(image, mask, target_size=(256, 256)):\n",
    "    # Random horizontal flip\n",
    "    if random.random() > 0.5:\n",
    "        image = hflip(image)\n",
    "        mask = hflip(mask)\n",
    "\n",
    "    # Random vertical flip\n",
    "    if random.random() > 0.5:\n",
    "        image = vflip(image)\n",
    "        mask = vflip(mask)\n",
    "\n",
    "    # Random rotation\n",
    "    angle = random.uniform(-15, 15)\n",
    "    image = rotate(image, angle, expand=False)\n",
    "    mask = rotate(mask, angle, expand=False)\n",
    "\n",
    "    # Resize\n",
    "    image = resize(image, target_size)\n",
    "    mask = resize(mask, target_size)\n",
    "\n",
    "    # To tensor + normalize\n",
    "    image = to_tensor(image)\n",
    "    image = normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    mask = to_tensor(mask)\n",
    "\n",
    "    return image, mask.float() # Ensure mask is [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save_segmentation(root_dir, partition, output_path, transform, target_size=(256, 256)):\n",
    "    with open(os.path.join(root_dir, 'annotations.json'), 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "\n",
    "    images = annotations['images']\n",
    "    corners = annotations[\"annotations\"]['corners']\n",
    "\n",
    "    valid_image_ids = list(range(len(corners)))\n",
    "\n",
    "    # Train/val/test split\n",
    "    train_ids, temp_ids = train_test_split(valid_image_ids, test_size=0.3, random_state=42) # 70% train\n",
    "    valid_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42) # 10% valid, 10% test\n",
    "\n",
    "    if partition == 'train':\n",
    "        splits = train_ids\n",
    "    elif partition == 'valid':\n",
    "        splits = valid_ids\n",
    "    elif partition == 'test':\n",
    "        splits = test_ids\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown partition: {partition}\")\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for img in images:\n",
    "        img_id = img['id']\n",
    "        if img_id not in splits:\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(root_dir, 'all_images', img['file_name'])\n",
    "        orig_image = Image.open(img_path).convert('RGB')\n",
    "        orig_w, orig_h = orig_image.size\n",
    "\n",
    "        # Step 1: Extract and scale corner points\n",
    "        corner_keys = [\"bottom_right\", \"top_right\", \"top_left\", \"bottom_left\"]\n",
    "        if img_id <= len(corners) - 1:\n",
    "            corner_data = corners[img_id]['corners']\n",
    "        else:\n",
    "            print(f\"Warning: No corner data for image ID {img_id}\")\n",
    "            continue\n",
    "\n",
    "        polygon = []\n",
    "        for key in corner_keys:\n",
    "            if key in corner_data:\n",
    "                x, y = corner_data[key]\n",
    "                x_scaled = int(x * (target_size[0] / orig_w))\n",
    "                y_scaled = int(y * (target_size[1] / orig_h))\n",
    "                polygon.append([x_scaled, y_scaled])\n",
    "            else:\n",
    "                polygon.append([0, 0])\n",
    "\n",
    "        polygon = np.array([polygon], dtype=np.int32)\n",
    "\n",
    "        # Step 2: Create binary mask (PIL)\n",
    "        mask_np = np.zeros(target_size, dtype=np.uint8)\n",
    "        cv2.fillPoly(mask_np, [polygon], 255)\n",
    "        mask_pil = Image.fromarray(mask_np)\n",
    "\n",
    "        if partition == 'train':\n",
    "            # Apply data augmentation for training partition\n",
    "            for _ in range(3):  # Duplicate training data 3 times\n",
    "                augmented_image, augmented_mask = apply_joint_transforms(orig_image, mask_pil, target_size)\n",
    "                data.append((augmented_image, augmented_mask))\n",
    "        else:\n",
    "            # Apply standard transform for validation/test partitions\n",
    "            image = transform(orig_image)\n",
    "            mask_pil = resize(mask_pil, target_size)\n",
    "            mask_pil = to_tensor(mask_pil).float()\n",
    "            mask = mask_pil.unsqueeze(0) if mask_pil.ndim == 2 else mask_pil  # (1, H, W)\n",
    "            data.append((image, mask))\n",
    "\n",
    "    torch.save(data, output_path)\n",
    "    print(f\"{partition} set saved to {output_path} with {len(data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set saved to train.pt with 4362 samples\n",
      "valid set saved to valid.pt with 312 samples\n",
      "test set saved to test.pt with 312 samples\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "preprocess_and_save_segmentation(\"../Shared\", \"train\", \"train.pt\", transform)\n",
    "preprocess_and_save_segmentation(\"../Shared\", \"valid\", \"valid.pt\", transform)\n",
    "preprocess_and_save_segmentation(\"../Shared\", \"test\", \"test.pt\", transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
