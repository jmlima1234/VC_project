{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "N_WORKERS = os.cpu_count()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "N_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/cristy17001/resnet50-piece-counter-combination/d3a137f472674ad9b9f3abeee560bf4c\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "\n",
    "\n",
    "# Create an instance of the Experiment class\n",
    "experiment = Experiment(\n",
    "    project_name=\"ResNet50 Piece Counter Combination\",  # Replace with your project name\n",
    "    workspace=\"cristy17001\"  # Replace with your workspace name\n",
    ")\n",
    "\n",
    "experiment.set_name(\"ResNet50 Piece Counter Combination 1\")\n",
    "experiment.log_parameters({\n",
    "    \"model\": \"resnet50\",\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"lr\": 1e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"loss_function\": \"BCE + MSE\",\n",
    "    \"scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"pretrained\": True,\n",
    "    \"patience\": 2,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": N_EPOCHS,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PreloadedDataset(Dataset):\n",
    "    def __init__(self, tensor_file):\n",
    "        self.data = torch.load(tensor_file)  # list of (img_tensor, presence_tensor, count_tensor)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_tensor, presence_tensor, count_tensor = self.data[idx]\n",
    "        return img_tensor, presence_tensor, count_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristiano\\AppData\\Local\\Temp\\ipykernel_3612\\592161780.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data = torch.load(tensor_file)  # list of (img_tensor, presence_tensor, count_tensor)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = PreloadedDataset(\"./train_data_noWarp.pt\")\n",
    "test_dataset = PreloadedDataset(\"./test_data_noWarp.pt\")\n",
    "val_dataset = PreloadedDataset(\"./val_data_noWarp.pt\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50MultiTask(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ResNet50MultiTask, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet-50\n",
    "        resnet = models.resnet50(pretrained=pretrained)\n",
    "\n",
    "        # Remove the classification head (fc layer)\n",
    "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])  # Output: [B, 2048, 1, 1]\n",
    "\n",
    "        # Flatten layer (ResNet output is [B, 2048, 1, 1])\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Classification head for presence map (64 outputs for 8x8 grid)\n",
    "        self.presence_head = nn.Sequential(\n",
    "            nn.Linear(2048, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "        )\n",
    "\n",
    "        # Regression head for piece count\n",
    "        self.count_head = nn.Sequential(\n",
    "            nn.Linear(2048, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Hardtanh(min_val=0, max_val=32)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)  # [B, 2048, 1, 1]\n",
    "        features = self.flatten(features)     # [B, 2048]\n",
    "        \n",
    "        presence_out = self.presence_head(features)  # [B, 64]\n",
    "        count_out = self.count_head(features)        # [B, 1]\n",
    "\n",
    "        return presence_out, count_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristiano\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cristiano\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50MultiTask().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "count_loss = nn.L1Loss()\n",
    "presence_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "PRESENCE_WEIGHT = 0.65\n",
    "COUNT_WEIGHT = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristiano\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 6.2699\n",
      "Validation Loss: 3.2042 | Presence Accuracy: 0.7093 | Count MAE: 8.6637\n",
      "Checkpoint saved at epoch 1 with Count MAE: 8.6637\n",
      "Epoch 2, Train Loss: 2.5568\n",
      "Validation Loss: 3.2243 | Presence Accuracy: 0.7194 | Count MAE: 7.6764\n",
      "Checkpoint saved at epoch 2 with Count MAE: 7.6764\n",
      "Epoch 3, Train Loss: 1.1257\n",
      "Validation Loss: 1.4874 | Presence Accuracy: 0.7412 | Count MAE: 3.1232\n",
      "Checkpoint saved at epoch 3 with Count MAE: 3.1232\n",
      "Epoch 4, Train Loss: 1.0084\n",
      "Validation Loss: 0.9652 | Presence Accuracy: 0.7356 | Count MAE: 1.6730\n",
      "Checkpoint saved at epoch 4 with Count MAE: 1.6730\n",
      "Epoch 5, Train Loss: 0.8778\n",
      "Validation Loss: 1.1134 | Presence Accuracy: 0.7379 | Count MAE: 2.3388\n",
      "Epoch 6, Train Loss: 0.7882\n",
      "Validation Loss: 0.7668 | Presence Accuracy: 0.7510 | Count MAE: 1.1682\n",
      "Checkpoint saved at epoch 6 with Count MAE: 1.1682\n",
      "Epoch 7, Train Loss: 0.7263\n",
      "Validation Loss: 0.8090 | Presence Accuracy: 0.7511 | Count MAE: 1.3181\n",
      "Epoch 8, Train Loss: 0.7502\n",
      "Validation Loss: 0.7610 | Presence Accuracy: 0.7593 | Count MAE: 1.2658\n",
      "Epoch 9, Train Loss: 0.8501\n",
      "Validation Loss: 0.9030 | Presence Accuracy: 0.7658 | Count MAE: 1.8211\n",
      "Epoch 10, Train Loss: 0.8007\n",
      "Validation Loss: 0.7415 | Presence Accuracy: 0.7645 | Count MAE: 1.1852\n",
      "Epoch 11, Train Loss: 0.7572\n",
      "Validation Loss: 0.8843 | Presence Accuracy: 0.7659 | Count MAE: 1.5547\n",
      "Epoch 12, Train Loss: 0.6743\n",
      "Validation Loss: 0.7736 | Presence Accuracy: 0.7682 | Count MAE: 1.2761\n",
      "Epoch 13, Train Loss: 0.6587\n",
      "Validation Loss: 0.6768 | Presence Accuracy: 0.7652 | Count MAE: 1.1085\n",
      "Checkpoint saved at epoch 13 with Count MAE: 1.1085\n",
      "Epoch 14, Train Loss: 0.6173\n",
      "Validation Loss: 0.8726 | Presence Accuracy: 0.7677 | Count MAE: 1.5935\n",
      "Epoch 15, Train Loss: 0.6226\n",
      "Validation Loss: 0.9208 | Presence Accuracy: 0.7680 | Count MAE: 1.6515\n",
      "Epoch 16, Train Loss: 0.6453\n",
      "Validation Loss: 0.7484 | Presence Accuracy: 0.7685 | Count MAE: 1.1860\n",
      "Epoch 17, Train Loss: 0.5859\n",
      "Validation Loss: 0.6673 | Presence Accuracy: 0.7665 | Count MAE: 0.9734\n",
      "Checkpoint saved at epoch 17 with Count MAE: 0.9734\n",
      "Epoch 18, Train Loss: 0.5490\n",
      "Validation Loss: 0.6472 | Presence Accuracy: 0.7672 | Count MAE: 0.9392\n",
      "Checkpoint saved at epoch 18 with Count MAE: 0.9392\n",
      "Epoch 19, Train Loss: 0.5934\n",
      "Validation Loss: 0.6509 | Presence Accuracy: 0.7673 | Count MAE: 0.9332\n",
      "Checkpoint saved at epoch 19 with Count MAE: 0.9332\n",
      "Epoch 20, Train Loss: 0.5632\n",
      "Validation Loss: 0.6311 | Presence Accuracy: 0.7674 | Count MAE: 0.9049\n",
      "Checkpoint saved at epoch 20 with Count MAE: 0.9049\n",
      "Epoch 21, Train Loss: 0.5828\n",
      "Validation Loss: 0.6518 | Presence Accuracy: 0.7670 | Count MAE: 0.9538\n",
      "Epoch 22, Train Loss: 0.5427\n",
      "Validation Loss: 0.6243 | Presence Accuracy: 0.7671 | Count MAE: 0.8853\n",
      "Checkpoint saved at epoch 22 with Count MAE: 0.8853\n",
      "Epoch 23, Train Loss: 0.5830\n",
      "Validation Loss: 0.6737 | Presence Accuracy: 0.7682 | Count MAE: 0.9756\n",
      "Epoch 24, Train Loss: 0.5642\n",
      "Validation Loss: 0.6386 | Presence Accuracy: 0.7668 | Count MAE: 0.9025\n",
      "Epoch 25, Train Loss: 0.5340\n",
      "Validation Loss: 0.6596 | Presence Accuracy: 0.7670 | Count MAE: 0.9636\n",
      "Epoch 26, Train Loss: 0.5831\n",
      "Validation Loss: 0.6494 | Presence Accuracy: 0.7679 | Count MAE: 0.9300\n",
      "Epoch 27, Train Loss: 0.5553\n",
      "Validation Loss: 0.6475 | Presence Accuracy: 0.7667 | Count MAE: 0.9258\n",
      "Epoch 28, Train Loss: 0.5690\n",
      "Validation Loss: 0.6526 | Presence Accuracy: 0.7675 | Count MAE: 0.9319\n",
      "Epoch 29, Train Loss: 0.5245\n",
      "Validation Loss: 0.6532 | Presence Accuracy: 0.7678 | Count MAE: 0.9343\n",
      "Epoch 30, Train Loss: 0.5598\n",
      "Validation Loss: 0.6490 | Presence Accuracy: 0.7675 | Count MAE: 0.9283\n",
      "Epoch 31, Train Loss: 0.4930\n",
      "Validation Loss: 0.6304 | Presence Accuracy: 0.7678 | Count MAE: 0.8936\n",
      "Epoch 32, Train Loss: 0.5428\n",
      "Validation Loss: 0.6552 | Presence Accuracy: 0.7679 | Count MAE: 0.9400\n",
      "Epoch 33, Train Loss: 0.5383\n",
      "Validation Loss: 0.6422 | Presence Accuracy: 0.7666 | Count MAE: 0.9219\n",
      "Epoch 34, Train Loss: 0.5196\n",
      "Validation Loss: 0.6485 | Presence Accuracy: 0.7678 | Count MAE: 0.9258\n",
      "Epoch 35, Train Loss: 0.5695\n",
      "Validation Loss: 0.6483 | Presence Accuracy: 0.7677 | Count MAE: 0.9327\n",
      "Epoch 36, Train Loss: 0.5509\n",
      "Validation Loss: 0.6397 | Presence Accuracy: 0.7678 | Count MAE: 0.9095\n",
      "Epoch 37, Train Loss: 0.5027\n",
      "Validation Loss: 0.6287 | Presence Accuracy: 0.7671 | Count MAE: 0.8925\n",
      "Epoch 38, Train Loss: 0.5332\n",
      "Validation Loss: 0.6416 | Presence Accuracy: 0.7670 | Count MAE: 0.9165\n",
      "Epoch 39, Train Loss: 0.5420\n",
      "Validation Loss: 0.6556 | Presence Accuracy: 0.7674 | Count MAE: 0.9411\n",
      "Epoch 40, Train Loss: 0.5869\n",
      "Validation Loss: 0.6440 | Presence Accuracy: 0.7669 | Count MAE: 0.9194\n",
      "Epoch 41, Train Loss: 0.5146\n",
      "Validation Loss: 0.6511 | Presence Accuracy: 0.7667 | Count MAE: 0.9372\n",
      "Epoch 42, Train Loss: 0.5025\n",
      "Validation Loss: 0.6474 | Presence Accuracy: 0.7671 | Count MAE: 0.9240\n",
      "Epoch 43, Train Loss: 0.5235\n",
      "Validation Loss: 0.6539 | Presence Accuracy: 0.7675 | Count MAE: 0.9369\n",
      "Epoch 44, Train Loss: 0.5502\n",
      "Validation Loss: 0.6521 | Presence Accuracy: 0.7675 | Count MAE: 0.9320\n",
      "Epoch 45, Train Loss: 0.5378\n",
      "Validation Loss: 0.6652 | Presence Accuracy: 0.7675 | Count MAE: 0.9587\n",
      "Epoch 46, Train Loss: 0.5471\n",
      "Validation Loss: 0.6397 | Presence Accuracy: 0.7669 | Count MAE: 0.9121\n",
      "Epoch 47, Train Loss: 0.5237\n",
      "Validation Loss: 0.6468 | Presence Accuracy: 0.7669 | Count MAE: 0.9244\n",
      "Epoch 48, Train Loss: 0.5196\n",
      "Validation Loss: 0.6445 | Presence Accuracy: 0.7677 | Count MAE: 0.9178\n",
      "Epoch 49, Train Loss: 0.5529\n",
      "Validation Loss: 0.6544 | Presence Accuracy: 0.7677 | Count MAE: 0.9389\n",
      "Epoch 50, Train Loss: 0.4829\n",
      "Validation Loss: 0.6465 | Presence Accuracy: 0.7672 | Count MAE: 0.9230\n",
      "Epoch 51, Train Loss: 0.4917\n",
      "Validation Loss: 0.6465 | Presence Accuracy: 0.7670 | Count MAE: 0.9268\n",
      "Epoch 52, Train Loss: 0.5428\n",
      "Validation Loss: 0.6437 | Presence Accuracy: 0.7666 | Count MAE: 0.9248\n",
      "Epoch 53, Train Loss: 0.5448\n",
      "Validation Loss: 0.6393 | Presence Accuracy: 0.7676 | Count MAE: 0.9153\n",
      "Epoch 54, Train Loss: 0.5400\n",
      "Validation Loss: 0.6507 | Presence Accuracy: 0.7668 | Count MAE: 0.9322\n",
      "Epoch 55, Train Loss: 0.5154\n",
      "Validation Loss: 0.6463 | Presence Accuracy: 0.7676 | Count MAE: 0.9238\n",
      "Epoch 56, Train Loss: 0.5429\n",
      "Validation Loss: 0.6406 | Presence Accuracy: 0.7679 | Count MAE: 0.9108\n",
      "Epoch 57, Train Loss: 0.4751\n",
      "Validation Loss: 0.6523 | Presence Accuracy: 0.7676 | Count MAE: 0.9340\n",
      "Epoch 58, Train Loss: 0.5157\n",
      "Validation Loss: 0.6731 | Presence Accuracy: 0.7676 | Count MAE: 0.9768\n",
      "Epoch 59, Train Loss: 0.5172\n",
      "Validation Loss: 0.6517 | Presence Accuracy: 0.7679 | Count MAE: 0.9324\n",
      "Epoch 60, Train Loss: 0.5819\n",
      "Validation Loss: 0.6386 | Presence Accuracy: 0.7671 | Count MAE: 0.9137\n",
      "Epoch 61, Train Loss: 0.5590\n",
      "Validation Loss: 0.6519 | Presence Accuracy: 0.7677 | Count MAE: 0.9353\n",
      "Epoch 62, Train Loss: 0.5706\n",
      "Validation Loss: 0.6468 | Presence Accuracy: 0.7675 | Count MAE: 0.9221\n",
      "Epoch 63, Train Loss: 0.5558\n",
      "Validation Loss: 0.6526 | Presence Accuracy: 0.7679 | Count MAE: 0.9344\n",
      "Epoch 64, Train Loss: 0.5187\n",
      "Validation Loss: 0.6583 | Presence Accuracy: 0.7678 | Count MAE: 0.9466\n",
      "Epoch 65, Train Loss: 0.5484\n",
      "Validation Loss: 0.6510 | Presence Accuracy: 0.7668 | Count MAE: 0.9369\n",
      "Epoch 66, Train Loss: 0.5398\n",
      "Validation Loss: 0.6633 | Presence Accuracy: 0.7673 | Count MAE: 0.9558\n",
      "Epoch 67, Train Loss: 0.5581\n",
      "Validation Loss: 0.6577 | Presence Accuracy: 0.7676 | Count MAE: 0.9454\n",
      "Epoch 68, Train Loss: 0.5280\n",
      "Validation Loss: 0.6477 | Presence Accuracy: 0.7674 | Count MAE: 0.9264\n",
      "Epoch 69, Train Loss: 0.5225\n",
      "Validation Loss: 0.6491 | Presence Accuracy: 0.7676 | Count MAE: 0.9274\n",
      "Epoch 70, Train Loss: 0.5314\n",
      "Validation Loss: 0.6454 | Presence Accuracy: 0.7675 | Count MAE: 0.9215\n",
      "Epoch 71, Train Loss: 0.5667\n",
      "Validation Loss: 0.6500 | Presence Accuracy: 0.7678 | Count MAE: 0.9278\n",
      "Epoch 72, Train Loss: 0.5333\n",
      "Validation Loss: 0.6494 | Presence Accuracy: 0.7674 | Count MAE: 0.9297\n",
      "Epoch 73, Train Loss: 0.5145\n",
      "Validation Loss: 0.6511 | Presence Accuracy: 0.7676 | Count MAE: 0.9330\n",
      "Epoch 74, Train Loss: 0.5417\n",
      "Validation Loss: 0.6409 | Presence Accuracy: 0.7670 | Count MAE: 0.9166\n",
      "Epoch 75, Train Loss: 0.5741\n",
      "Validation Loss: 0.6510 | Presence Accuracy: 0.7675 | Count MAE: 0.9303\n",
      "Epoch 76, Train Loss: 0.5158\n",
      "Validation Loss: 0.6474 | Presence Accuracy: 0.7674 | Count MAE: 0.9261\n",
      "Epoch 77, Train Loss: 0.5098\n",
      "Validation Loss: 0.6523 | Presence Accuracy: 0.7679 | Count MAE: 0.9356\n",
      "Epoch 78, Train Loss: 0.5323\n",
      "Validation Loss: 0.6490 | Presence Accuracy: 0.7669 | Count MAE: 0.9290\n",
      "Epoch 79, Train Loss: 0.5138\n",
      "Validation Loss: 0.6532 | Presence Accuracy: 0.7668 | Count MAE: 0.9391\n",
      "Epoch 80, Train Loss: 0.5353\n",
      "Validation Loss: 0.6486 | Presence Accuracy: 0.7667 | Count MAE: 0.9279\n",
      "Epoch 81, Train Loss: 0.5205\n",
      "Validation Loss: 0.6363 | Presence Accuracy: 0.7679 | Count MAE: 0.9038\n",
      "Epoch 82, Train Loss: 0.5698\n",
      "Validation Loss: 0.6540 | Presence Accuracy: 0.7676 | Count MAE: 0.9365\n",
      "Epoch 83, Train Loss: 0.5429\n",
      "Validation Loss: 0.6571 | Presence Accuracy: 0.7673 | Count MAE: 0.9412\n",
      "Epoch 84, Train Loss: 0.5847\n",
      "Validation Loss: 0.6389 | Presence Accuracy: 0.7676 | Count MAE: 0.9072\n",
      "Epoch 85, Train Loss: 0.5453\n",
      "Validation Loss: 0.6515 | Presence Accuracy: 0.7664 | Count MAE: 0.9389\n",
      "Epoch 86, Train Loss: 0.5495\n",
      "Validation Loss: 0.6507 | Presence Accuracy: 0.7678 | Count MAE: 0.9303\n",
      "Epoch 87, Train Loss: 0.4981\n",
      "Validation Loss: 0.6615 | Presence Accuracy: 0.7676 | Count MAE: 0.9508\n",
      "Epoch 88, Train Loss: 0.5118\n",
      "Validation Loss: 0.6596 | Presence Accuracy: 0.7677 | Count MAE: 0.9462\n",
      "Epoch 89, Train Loss: 0.5400\n",
      "Validation Loss: 0.6590 | Presence Accuracy: 0.7679 | Count MAE: 0.9449\n",
      "Epoch 90, Train Loss: 0.5243\n",
      "Validation Loss: 0.6444 | Presence Accuracy: 0.7670 | Count MAE: 0.9247\n",
      "Epoch 91, Train Loss: 0.5612\n",
      "Validation Loss: 0.6435 | Presence Accuracy: 0.7671 | Count MAE: 0.9163\n",
      "Epoch 92, Train Loss: 0.5506\n",
      "Validation Loss: 0.6490 | Presence Accuracy: 0.7676 | Count MAE: 0.9255\n",
      "Epoch 93, Train Loss: 0.4956\n",
      "Validation Loss: 0.6559 | Presence Accuracy: 0.7675 | Count MAE: 0.9405\n",
      "Epoch 94, Train Loss: 0.5224\n",
      "Validation Loss: 0.6334 | Presence Accuracy: 0.7679 | Count MAE: 0.9017\n",
      "Epoch 95, Train Loss: 0.5084\n",
      "Validation Loss: 0.6490 | Presence Accuracy: 0.7673 | Count MAE: 0.9279\n",
      "Epoch 96, Train Loss: 0.5325\n",
      "Validation Loss: 0.6420 | Presence Accuracy: 0.7665 | Count MAE: 0.9181\n",
      "Epoch 97, Train Loss: 0.5083\n",
      "Validation Loss: 0.6545 | Presence Accuracy: 0.7678 | Count MAE: 0.9358\n",
      "Epoch 98, Train Loss: 0.5955\n",
      "Validation Loss: 0.6425 | Presence Accuracy: 0.7669 | Count MAE: 0.9217\n",
      "Epoch 99, Train Loss: 0.5839\n",
      "Validation Loss: 0.6584 | Presence Accuracy: 0.7675 | Count MAE: 0.9434\n",
      "Epoch 100, Train Loss: 0.4980\n",
      "Validation Loss: 0.6505 | Presence Accuracy: 0.7673 | Count MAE: 0.9304\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "\n",
    "best_count_mae = np.inf  # Initialize with infinity\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for images, presence_maps, counts in train_loader:\n",
    "        images = images.to(device)\n",
    "        presence_maps = presence_maps.to(device)\n",
    "        counts = counts.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs_presence, outputs_count = model(images)\n",
    "        loss_presence = presence_loss(outputs_presence, presence_maps)\n",
    "        loss_count = count_loss(outputs_count.squeeze(1), counts)\n",
    "        loss = PRESENCE_WEIGHT * loss_presence + COUNT_WEIGHT * loss_count\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_presence_preds = []\n",
    "    all_presence_labels = []\n",
    "    all_count_preds = []\n",
    "    all_count_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, presence_maps, counts in validation_loader:\n",
    "            images = images.to(device)\n",
    "            presence_maps = presence_maps.to(device)\n",
    "            counts = counts.to(device)\n",
    "\n",
    "            presence_pred, count_pred = model(images)\n",
    "\n",
    "            loss_presence = presence_loss(presence_pred, presence_maps)\n",
    "            loss_count = count_loss(count_pred.squeeze(1), counts)\n",
    "            val_loss += (PRESENCE_WEIGHT * loss_presence + COUNT_WEIGHT * loss_count).item()\n",
    "\n",
    "            all_presence_preds.append(presence_pred.detach().cpu())\n",
    "            all_presence_labels.append(presence_maps.detach().cpu())\n",
    "            all_count_preds.append(count_pred.detach().cpu())\n",
    "            all_count_labels.append(counts.detach().cpu())\n",
    "\n",
    "    val_loss /= len(validation_loader)\n",
    "\n",
    "    all_presence_preds = torch.cat(all_presence_preds).numpy()\n",
    "    all_presence_labels = torch.cat(all_presence_labels).numpy()\n",
    "    all_count_preds = torch.cat(all_count_preds).numpy()\n",
    "    all_count_labels = torch.cat(all_count_labels).numpy()\n",
    "\n",
    "    all_presence_preds_binary = (all_presence_preds > 0.5).astype(int)\n",
    "    all_presence_labels_int = all_presence_labels.astype(int)\n",
    "\n",
    "    presence_accuracy = accuracy_score(all_presence_labels_int.flatten(), all_presence_preds_binary.flatten())\n",
    "    count_mae = mean_absolute_error(all_count_labels, all_count_preds)\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.4f} | Presence Accuracy: {presence_accuracy:.4f} | Count MAE: {count_mae:.4f}\")\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save checkpoint if this is the best count_mae so far\n",
    "    if count_mae < best_count_mae:\n",
    "        best_count_mae = count_mae\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'count_mae': count_mae,\n",
    "        }, 'best_checkpoint_combination.pt')\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1} with Count MAE: {count_mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
