{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Grid Line help detect squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_grid_lines(image_rgb, show_lines=True, edge_threshold=20):\n",
    "    height, width = image_rgb.shape[:2]\n",
    "\n",
    "    gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (17, 13), 0)\n",
    "\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    edges = cv2.dilate(edges, np.ones((3, 3), np.uint8), iterations=1)\n",
    "\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=80, minLineLength=100, maxLineGap=10)\n",
    "    \n",
    "    if lines is None:\n",
    "        print(\"No lines found\")\n",
    "        return [], []\n",
    "\n",
    "    horizontal_lines = []\n",
    "    vertical_lines = []\n",
    "\n",
    "    for x1, y1, x2, y2 in lines[:, 0]:\n",
    "        angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "        if abs(angle) < 10:\n",
    "            horizontal_lines.append((x1, y1, x2, y2))\n",
    "        elif abs(angle - 90) < 10 or abs(angle + 90) < 10:\n",
    "            vertical_lines.append((x1, y1, x2, y2))\n",
    "\n",
    "    def merge_line_coords(lines, axis='y', threshold=30):\n",
    "        if not lines:\n",
    "            return []\n",
    "        coords = [int((y1 + y2) / 2) if axis == 'y' else int((x1 + x2) / 2) for x1, y1, x2, y2 in lines]\n",
    "        coords = sorted(coords)\n",
    "        merged = []\n",
    "        current = coords[0]\n",
    "        for val in coords[1:]:\n",
    "            if abs(val - current) < threshold:\n",
    "                current = int((current + val) / 2)\n",
    "            else:\n",
    "                merged.append(current)\n",
    "                current = val\n",
    "        merged.append(current)\n",
    "        return merged\n",
    "\n",
    "    merged_horizontal = merge_line_coords(horizontal_lines, axis='y')\n",
    "    merged_vertical = merge_line_coords(vertical_lines, axis='x')\n",
    "\n",
    "    # Remove lines too close to image edges\n",
    "    merged_horizontal = [y for y in merged_horizontal if edge_threshold < y < (height - edge_threshold)]\n",
    "    merged_vertical = [x for x in merged_vertical if edge_threshold < x < (width - edge_threshold)]\n",
    "\n",
    "    filled_horizontal = []\n",
    "    filled_vertical = []\n",
    "\n",
    "    def fill_missing_lines(existing, filled, total_lines, size, tolerance=40):\n",
    "        print(f\"Filling missing lines: {len(existing)} found, {total_lines} expected\")\n",
    "        ideal_positions = list(np.linspace(0, size, total_lines + 2, dtype=int)[1:-1])\n",
    "        for pos in ideal_positions:\n",
    "            if not any(abs(pos - e) < tolerance for e in existing):\n",
    "                existing.append(pos)\n",
    "                filled.append(pos)\n",
    "        existing.sort()\n",
    "        return existing\n",
    "\n",
    "    if len(merged_horizontal) < 7:\n",
    "        merged_horizontal = fill_missing_lines(merged_horizontal, filled_horizontal, 7, height)\n",
    "    if len(merged_vertical) < 7:\n",
    "        merged_vertical = fill_missing_lines(merged_vertical, filled_vertical, 7, width)\n",
    "        \n",
    "    # If we don't have exactly 7 lines in each direction, use equally spaced lines as fallback\n",
    "    if len(merged_horizontal) != 7 or len(merged_vertical) != 7:\n",
    "        print(f\"Insufficient grid lines detected: {len(merged_horizontal)} horizontal, {len(merged_vertical)} vertical\")\n",
    "        print(\"Falling back to equally spaced grid lines\")\n",
    "\n",
    "        # Generate 9 lines (including borders)\n",
    "        horizontal_all = list(np.linspace(0, height, 9, dtype=int))\n",
    "        vertical_all = list(np.linspace(0, width, 9, dtype=int))\n",
    "\n",
    "        # Take internal 7 lines (excluding the first and last, which are borders)\n",
    "        merged_horizontal = horizontal_all[1:-1]\n",
    "        merged_vertical = vertical_all[1:-1]\n",
    "\n",
    "        # Mark all as filled (fallback)\n",
    "        filled_horizontal = merged_horizontal.copy()\n",
    "        filled_vertical = merged_vertical.copy()\n",
    "\n",
    "    if show_lines:\n",
    "        merged_image = image_rgb.copy()\n",
    "        for y in merged_horizontal:\n",
    "            color = (255, 0, 255) if y in filled_horizontal else (0, 0, 255)  # Magenta or Blue\n",
    "            cv2.line(merged_image, (0, y), (merged_image.shape[1], y), color, 3)\n",
    "\n",
    "        for x in merged_vertical:\n",
    "            color = (0, 255, 255) if x in filled_vertical else (0, 255, 0)  # Cyan or Green\n",
    "            cv2.line(merged_image, (x, 0), (x, merged_image.shape[0]), color, 3)\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(merged_image)\n",
    "        plt.title(\"Filtered + Filled Grid Lines (Distinct Colors)\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    return merged_horizontal, merged_vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide warped into Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "def process_image(key, warped_results):\n",
    "    h_lines, v_lines = detect_grid_lines(warped_results[key]['warped_image'], show_lines=False)\n",
    "\n",
    "    if len(h_lines) != 7 or len(v_lines) != 7:\n",
    "        print(f\"Not enough grid lines detected in {key}.\")\n",
    "        return None\n",
    "\n",
    "    height, width = warped_results[key]['warped_image'].shape[:2]\n",
    "    h_lines_full = [0] + sorted(h_lines) + [height]\n",
    "    v_lines_full = [0] + sorted(v_lines) + [width]\n",
    "\n",
    "    squares = []\n",
    "    square_centers = []\n",
    "    square_bounds = []\n",
    "\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            y1, y2 = h_lines_full[i], h_lines_full[i + 1]\n",
    "            x1, x2 = v_lines_full[j], v_lines_full[j + 1]\n",
    "            square = warped_results[key]['warped_image'][y1:y2, x1:x2]\n",
    "            rank = 8 - i\n",
    "            file = files[j]\n",
    "            label = f\"{file}{rank}\"\n",
    "            # Resize the square image to 224x224\n",
    "            square_resized = cv2.resize(square, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "            squares.append({\"position\": (i, j), \"label\": label, \"image\": square_resized})\n",
    "            center_x = (x1 + x2) // 2\n",
    "            center_y = (y1 + y2) // 2\n",
    "            square_centers.append((center_x, center_y))\n",
    "            square_bounds.append((x1, y1, x2, y2))\n",
    "\n",
    "    warped_results[key]['squares'] = squares\n",
    "    return warped_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Truth Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2078 training input files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "training_inputs_dir = \"../Shared/training_inputs/matrices\"\n",
    "training_files = [f for f in os.listdir(training_inputs_dir) if f.endswith('.json')]\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for fname in training_files:\n",
    "    path = os.path.join(training_inputs_dir, fname)\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        if data.get(\"corners\"):\n",
    "            training_data.append({\n",
    "                \"file_name\": data.get(\"file_name\"),\n",
    "                \"image_id\" : data.get(\"image_id\"),\n",
    "                \"piece_count\": data.get(\"piece_count\"),\n",
    "                \"presence_matrix\": np.flipud(data.get(\"presence_matrix\")).tolist(),\n",
    "                \"piece_type_matrix\": data.get(\"piece_type_matrix\"),\n",
    "                \"corners\": data.get(\"corners\")\n",
    "            })\n",
    "\n",
    "print(f\"Loaded {len(training_data)} training input files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warp the image using corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def warp_with_corners(image, corners_dict, board_size=800):\n",
    "    \"\"\"\n",
    "    Warps the input image using the provided corners so that the bottom-left corner\n",
    "    in corners_dict becomes the bottom-left of the output image.\n",
    "    corners_dict: dict with keys 'top_left', 'top_right', 'bottom_left', 'bottom_right'\n",
    "    image: input image (BGR or RGB)\n",
    "    \"\"\"\n",
    "    # Order: [top_left, top_right, bottom_left, bottom_right]\n",
    "    src_corners = np.array([\n",
    "        corners_dict['top_left'],\n",
    "        corners_dict['top_right'],\n",
    "        corners_dict['bottom_left'],\n",
    "        corners_dict['bottom_right']\n",
    "    ], dtype=\"float32\")\n",
    "\n",
    "    # The destination corners: [top_left, top_right, bottom_left, bottom_right]\n",
    "    dst_corners = np.array([\n",
    "        [0, 0],\n",
    "        [board_size - 1, 0],\n",
    "        [0, board_size - 1],\n",
    "        [board_size - 1, board_size - 1]\n",
    "    ], dtype=\"float32\")\n",
    "\n",
    "    # Find the perspective transform matrix\n",
    "    matrix = cv2.getPerspectiveTransform(src_corners, dst_corners)\n",
    "    warped = cv2.warpPerspective(image, matrix, (board_size, board_size))\n",
    "\n",
    "    return warped, matrix, src_corners, dst_corners\n",
    "\n",
    "images_dir = \"../Shared/all_images\"\n",
    "warped_results = {}\n",
    "for entry in training_data:\n",
    "    img_path = os.path.join(images_dir, entry['file_name'])\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Image not found: {img_path}\")\n",
    "        continue\n",
    "    img = cv2.imread(img_path)\n",
    "    corners = entry['corners']\n",
    "    warped_img, matrix, src, dst = warp_with_corners(img, corners)\n",
    "    warped_results[entry['file_name']] = {\n",
    "        'warped_image': warped_img,\n",
    "        'matrix': matrix,\n",
    "        'src_corners': src,\n",
    "        'dst_corners': dst\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fname in warped_results.keys():\n",
    "#     warped_results = process_image(fname, warped_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 1442, 'val': 330, 'test': 306}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "json_path = Path(\"../Shared/annotations.json\")  # Update if needed\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Load chessred2k split image IDs\n",
    "chessred2k_splits = {}\n",
    "for split in ['train', 'val', 'test']:\n",
    "    chessred2k_splits[split] = data['splits']['chessred2k'][split]['image_ids']\n",
    "\n",
    "print({k: len(v) for k, v in chessred2k_splits.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristiano\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cristiano\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Cristiano\\AppData\\Local\\Temp\\ipykernel_24344\\3178594598.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing lines: 4 found, 7 expected\n",
      "Filling missing lines: 5 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Filling missing lines: 4 found, 7 expected\n",
      "Insufficient grid lines detected: 9 horizontal, 7 vertical\n",
      "Falling back to equally spaced grid lines\n",
      "Filling missing lines: 5 found, 7 expected\n",
      "Filling missing lines: 5 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Insufficient grid lines detected: 7 horizontal, 8 vertical\n",
      "Falling back to equally spaced grid lines\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Filling missing lines: 5 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n",
      "Filling missing lines: 6 found, 7 expected\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "\n",
    "def load_model(model, path):\n",
    "    checkpoint = torch.load(path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint)\n",
    "    model.eval()\n",
    "    return model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Load model\n",
    "# MODEL_NAME = 'resnet50'\n",
    "# model = models.resnet50(weights=False)\n",
    "# model.fc = nn.Linear(model.fc.in_features, 1)  # Binary classification\n",
    "# model = load_model(model, './checkpoints_resnet50_1_squares/best_piece_classifier.pt')\n",
    "\n",
    "# # Load MobileNetV3 Large model\n",
    "# MODEL_NAME = 'MobileNetV3'\n",
    "# model = models.mobilenet_v3_large(weights=False)\n",
    "# num_features = model.classifier[3].in_features\n",
    "# model.classifier[3] = nn.Linear(num_features, 1)\n",
    "# model = load_model(model, './checkpoints_mobileNetV3_squares/best_piece_classifier.pt')\n",
    "\n",
    "# Load SqueezeNet model\n",
    "MODEL_NAME = 'SqueezeNet'\n",
    "model = models.squeezenet1_0(pretrained=False)\n",
    "model.classifier[1] = nn.Conv2d(512, 1, kernel_size=1)\n",
    "model.num_classes = 1\n",
    "\n",
    "class SqueezeNetBinary(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base = base_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        return x.view(x.size(0), -1)  # Flatten to shape [batch_size, 1]\n",
    "\n",
    "model = SqueezeNetBinary(model)\n",
    "model = load_model(model, './checkpoints_SqueezeNet_1.0_squares/best_piece_classifier.pt')\n",
    "\n",
    "# Preprocessing for ResNet50\n",
    "preprocess = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Split and image filtering\n",
    "train_image_ids = set(chessred2k_splits['test'])\n",
    "train_entries = [entry for entry in training_data if entry['image_id'] in train_image_ids]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for entry in train_entries:\n",
    "    fname = entry['file_name']\n",
    "    if fname not in warped_results:\n",
    "        print(f\"Warped image not found for {fname}\")\n",
    "        continue\n",
    "\n",
    "    warped_results = process_image(fname, warped_results)\n",
    "    squares = warped_results[fname].get('squares', [])\n",
    "\n",
    "    # Skip if no squares found\n",
    "    if not squares:\n",
    "        continue\n",
    "\n",
    "    # Preprocess all 64 squares into a batch\n",
    "    batch_tensors = []\n",
    "    for square in squares:\n",
    "        img = square['image']\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        tensor = preprocess(img_rgb)\n",
    "        batch_tensors.append(tensor)\n",
    "\n",
    "    # Create single batch tensor\n",
    "    input_batch = torch.stack(batch_tensors).to(device)  # Shape: [64, 3, 224, 224]\n",
    "\n",
    "    # Inference in one go\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_batch)                       # [64, 1]\n",
    "        probs = torch.sigmoid(logits).squeeze(1)          # [64]\n",
    "\n",
    "    # Store predictions\n",
    "    predictions = []\n",
    "    for square, logit, prob in zip(squares, logits.squeeze(1), probs):\n",
    "        predictions.append({\n",
    "            'label': square['label'],\n",
    "            'logit': logit.item(),\n",
    "            'prob': prob.item()\n",
    "        })\n",
    "\n",
    "    results[fname] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Model SqueezeNet -----\n",
      "\n",
      "----- Per-Square Classification Metrics -----\n",
      "Accuracy: 99.68341503267973 %\n",
      "Precision: 99.13276568905708 %\n",
      "Recall: 99.88878296790594 %\n",
      "F1 Score: 99.50933839822729 %\n",
      "Confusion Matrix:\n",
      " [[13235    55]\n",
      " [    7  6287]]\n",
      "\n",
      "----- Per-Image Piece Count Metrics -----\n",
      "MSE (count-level, thresholded): 0.3202614379084967\n",
      "RMSE (count-level, thresholded): 0.5659164584181102\n",
      "MAE (count-level, thresholded): 0.20261437908496732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, mean_squared_error, mean_absolute_error\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# --- Per-Square Evaluation (classification-style) ---\n",
    "y_true = []\n",
    "y_pred = []  # Binary class: 0 or 1\n",
    "y_prob = []  # Probabilistic output: sigmoid\n",
    "\n",
    "file_to_presence = {entry['file_name']: entry['presence_matrix'] for entry in training_data}\n",
    "\n",
    "for fname, predictions in results.items():\n",
    "    presence_matrix = file_to_presence.get(fname)\n",
    "    if presence_matrix is None:\n",
    "        continue\n",
    "    gt_flat = np.array(presence_matrix).flatten()\n",
    "    for idx, pred in enumerate(predictions):\n",
    "        y_true.append(gt_flat[idx])\n",
    "        y_prob.append(pred['prob'])\n",
    "        y_pred.append(int(pred['prob'] > 0.5))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_prob = np.array(y_prob)\n",
    "\n",
    "# Classification metrics\n",
    "print(f\"\\n----- Model {MODEL_NAME} -----\")\n",
    "print()\n",
    "print(\"----- Per-Square Classification Metrics -----\")\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred)*100, \"%\") \n",
    "print(\"Precision:\", precision_score(y_true, y_pred, zero_division=0)*100, \"%\")\n",
    "print(\"Recall:\", recall_score(y_true, y_pred, zero_division=0)*100, \"%\")\n",
    "print(\"F1 Score:\", f1_score(y_true, y_pred, zero_division=0)*100, \"%\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# --- Per-Image Evaluation (counting pieces per board) ---\n",
    "true_counts = []\n",
    "pred_counts = []\n",
    "soft_pred_counts = []\n",
    "\n",
    "for fname, predictions in results.items():\n",
    "    presence_matrix = file_to_presence.get(fname)\n",
    "    if presence_matrix is None:\n",
    "        continue\n",
    "    true_count = np.array(presence_matrix).sum()\n",
    "    thresholded_count = sum(pred['prob'] > 0.5 for pred in predictions)\n",
    "    soft_count = sum(pred['prob'] for pred in predictions)\n",
    "\n",
    "    true_counts.append(true_count)\n",
    "    pred_counts.append(thresholded_count)\n",
    "    soft_pred_counts.append(soft_count)\n",
    "\n",
    "# Thresholded count metrics\n",
    "mse_count = mean_squared_error(true_counts, pred_counts)\n",
    "rmse_count = np.sqrt(mse_count)\n",
    "mae_count = mean_absolute_error(true_counts, pred_counts)\n",
    "\n",
    "print(\"\\n----- Per-Image Piece Count Metrics -----\")\n",
    "print(\"MSE (count-level, thresholded):\", mse_count)\n",
    "print(\"RMSE (count-level, thresholded):\", rmse_count)\n",
    "print(\"MAE (count-level, thresholded):\", mae_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
