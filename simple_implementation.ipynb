{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for tunning\n",
    "\n",
    "BASE_IMG_FOLDER = './VC_2425_Project_public/images/'\n",
    "\n",
    "# Parameters for the image processing\n",
    "SHOW_DEBUG_IMGS = \"NONE\" # [\"LINES\", \"WARP\", \"ALL\", \"NONE\"]\n",
    "CORNER_HORSE_TEMPLATE_PATH = \"./cornerHorse_templates/\"\n",
    "SAVE_DEBUG_IMGS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images for the corner horses and store them in a list\n",
    "CORNER_HORSES_TEMPLATES = []\n",
    "for filename in os.listdir(CORNER_HORSE_TEMPLATE_PATH):\n",
    "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "        img = cv2.imread(os.path.join(CORNER_HORSE_TEMPLATE_PATH, filename))\n",
    "        CORNER_HORSES_TEMPLATES.append(img)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_original_and_gray(image_path):\n",
    "    original_img = cv2.imread(image_path)\n",
    "    rgb_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Wood removal by color thresholding (targeting brown/wooden colors)\n",
    "    hsv_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define range for brown/wooden colors in HSV\n",
    "    lower_brown = np.array([2, 11, 11])\n",
    "    upper_brown = np.array([60, 255, 255]) \n",
    "    \n",
    "    # Create mask for wood\n",
    "    wood_mask = cv2.inRange(hsv_img, lower_brown, upper_brown)\n",
    "    \n",
    "    # Invert the mask to keep non-wood parts\n",
    "    wood_mask_inv = cv2.bitwise_not(wood_mask)\n",
    "    \n",
    "    # Apply the mask to the original image\n",
    "    no_wood_img = cv2.bitwise_and(original_img, original_img, mask=wood_mask_inv)\n",
    "    \n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_img = cv2.cvtColor(no_wood_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display images to show the process\n",
    "    if SHOW_DEBUG_IMGS == \"ALL\":\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Original image - left\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(rgb_img)\n",
    "        plt.axis('off')\n",
    "        plt.title('Original RGB Image')\n",
    "\n",
    "        # Final grayscale image - right\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(gray_img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title('Without Wood Grayscale Image')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return original_img, gray_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(gray_img, blur_kernel_size=17, intensity_factor=1.3, laplacian_kernel_size=3):\n",
    "    blurred = cv2.GaussianBlur(gray_img, (blur_kernel_size, blur_kernel_size), 0)\n",
    "    adjusted_img = cv2.convertScaleAbs(blurred, alpha=intensity_factor, beta=0)\n",
    "\n",
    "    # Morphological opening to remove small details like pieces\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    opened = cv2.morphologyEx(adjusted_img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    laplacian = cv2.Laplacian(opened, cv2.CV_64F, ksize=laplacian_kernel_size)\n",
    "    laplacian = cv2.convertScaleAbs(laplacian)\n",
    "\n",
    "    # OTSU + optional manual offset to suppress weak edges\n",
    "    otsu_thresh_val, _ = cv2.threshold(laplacian, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    _, binary_img = cv2.threshold(laplacian, otsu_thresh_val + 20, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    return binary_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lines(binary_img, min_line_length=50, max_line_gap=50):\n",
    "    # Canny edge detection with lower threshold\n",
    "    canny_image = cv2.Canny(binary_img, 50, 200)  # Tuning thresholds to capture better edges\n",
    "\n",
    "    # Use dilation to reinforce edges\n",
    "    kernel = np.ones((13, 13), np.uint8)\n",
    "    dilation_image = cv2.dilate(canny_image, kernel, iterations=1)\n",
    "    \n",
    "    # Hough Lines transform for line detection\n",
    "    lines = cv2.HoughLinesP(dilation_image, 1, np.pi / 180, threshold=500, \n",
    "                            minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "\n",
    "    # Create an image to store the detected lines\n",
    "    black_image = np.zeros_like(dilation_image)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(black_image, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "    \n",
    "    return black_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise_components(line_img, min_area=1000, keep_largest=True):\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(line_img, connectivity=8)\n",
    "    \n",
    "    # Create a black image to store the final result\n",
    "    final_image = np.zeros_like(line_img)\n",
    "    \n",
    "    if keep_largest:\n",
    "        # Get the areas of all components (ignoring the background)\n",
    "        areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "        \n",
    "        # Find the label of the largest component\n",
    "        max_label = 1 + np.argmax(areas)\n",
    "        \n",
    "        # Keep only the largest component\n",
    "        final_image[labels == max_label] = 255\n",
    "    else:\n",
    "        # If not keeping only the largest component, keep components above the min_area threshold\n",
    "        for label in range(1, num_labels):\n",
    "            area = stats[label, cv2.CC_STAT_AREA]\n",
    "            if area >= min_area:\n",
    "                final_image[labels == label] = 255\n",
    "\n",
    "    if (SHOW_DEBUG_IMGS == \"ALL\" or SHOW_DEBUG_IMGS == \"LINES\"):\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(\"Only Board Lines (Filtered)\", fontsize=12)\n",
    "        plt.imshow(final_image, cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    return final_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chessboard_contour(line_img):\n",
    "    contours, _ = cv2.findContours(line_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    \n",
    "    if contours:\n",
    "        return contours[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_corners(corners):\n",
    "    sorted_by_y = sorted(corners, key=lambda p: p[1])\n",
    "    top_two = sorted(sorted_by_y[:2], key=lambda p: p[0])\n",
    "    bottom_two = sorted(sorted_by_y[2:], key=lambda p: p[0])\n",
    "    return np.array([top_two[0], top_two[1], bottom_two[0], bottom_two[1]], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_chessboard(gray_img, original_img, contour, board_size=800):\n",
    "    epsilon = 0.05 * cv2.arcLength(contour, True)\n",
    "    approx_corners = cv2.approxPolyDP(contour, epsilon, True)\n",
    "    if len(approx_corners) == 4:\n",
    "        corners = np.squeeze(approx_corners)\n",
    "        ordered_corners = order_corners(corners)\n",
    "        dst_corners = np.array([\n",
    "            [0, 0], [board_size - 1, 0],\n",
    "            [0, board_size - 1], [board_size - 1, board_size - 1]\n",
    "        ], dtype=\"float32\")\n",
    "        matrix = cv2.getPerspectiveTransform(ordered_corners, dst_corners)\n",
    "        warped_board = cv2.warpPerspective(gray_img, matrix, (board_size, board_size))\n",
    "        \n",
    "        # Also warp the original RGB image\n",
    "        warped_original = cv2.warpPerspective(original_img, matrix, (board_size, board_size))\n",
    "        warped_original_rgb = cv2.cvtColor(warped_original, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if (SHOW_DEBUG_IMGS == \"ALL\" or SHOW_DEBUG_IMGS == \"LINES\" or SHOW_DEBUG_IMGS == \"WARP\"):\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.title(\"Warped Chessboard (Grayscale)\", fontsize=12)\n",
    "            plt.imshow(warped_board, cmap=\"gray\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.title(\"Warped Chessboard (Original)\", fontsize=12)\n",
    "            plt.imshow(warped_original_rgb)\n",
    "            plt.axis('off')\n",
    "            \n",
    "        # Return the warp matrix as well to allow for reverting the transform\n",
    "        return warped_board, warped_original_rgb, matrix, ordered_corners, dst_corners\n",
    "    else:\n",
    "        print(\"Error: Did not find exactly 4 corners!\")\n",
    "        return None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chessboard_image(image_path):\n",
    "    original_img, gray_img = show_original_and_gray(image_path)\n",
    "    otsu_binary = preprocess_image(gray_img)\n",
    "    line_img = detect_lines(otsu_binary)\n",
    "    clean_line_img = remove_noise_components(line_img)\n",
    "    contour = find_chessboard_contour(clean_line_img)\n",
    "    if contour is not None:\n",
    "        return warp_chessboard(gray_img, original_img, contour)\n",
    "    else:\n",
    "        print(\"Chessboard contour not found!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def detect_grid_lines(image_rgb, show_lines=True, edge_threshold=20):\n",
    "    height, width = image_rgb.shape[:2]\n",
    "\n",
    "    gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (17, 13), 0)\n",
    "\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    edges = cv2.dilate(edges, np.ones((3, 3), np.uint8), iterations=1)\n",
    "\n",
    "    # if show_lines:\n",
    "    #     plt.figure(figsize=(12, 6))\n",
    "    #     plt.subplot(1, 2, 1)\n",
    "    #     plt.imshow(image_rgb)\n",
    "    #     plt.title(\"Original Image\")\n",
    "    #     plt.axis(\"off\")\n",
    "        \n",
    "    #     plt.subplot(1, 2, 2)\n",
    "    #     plt.imshow(edges, cmap='gray')\n",
    "    #     plt.title(\"Dilated Canny Edges\")\n",
    "    #     plt.axis(\"off\")\n",
    "    #     plt.tight_layout()\n",
    "    #     plt.show()\n",
    "\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=80, minLineLength=100, maxLineGap=10)\n",
    "    \n",
    "    if lines is None:\n",
    "        print(\"No lines found\")\n",
    "        return [], []\n",
    "\n",
    "    horizontal_lines = []\n",
    "    vertical_lines = []\n",
    "\n",
    "    for x1, y1, x2, y2 in lines[:, 0]:\n",
    "        angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "        if abs(angle) < 10:\n",
    "            horizontal_lines.append((x1, y1, x2, y2))\n",
    "        elif abs(angle - 90) < 10 or abs(angle + 90) < 10:\n",
    "            vertical_lines.append((x1, y1, x2, y2))\n",
    "\n",
    "    # if show_lines:\n",
    "    #     hough_image = image_rgb.copy()\n",
    "    #     for x1, y1, x2, y2 in horizontal_lines + vertical_lines:\n",
    "    #         cv2.line(hough_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    #     plt.figure(figsize=(8, 8))\n",
    "    #     plt.imshow(hough_image)\n",
    "    #     plt.title(\"Detected Lines (HoughLinesP)\")\n",
    "    #     plt.axis(\"off\")\n",
    "    #     plt.show()\n",
    "\n",
    "    def merge_line_coords(lines, axis='y', threshold=15):\n",
    "        if not lines:\n",
    "            return []\n",
    "        coords = [int((y1 + y2) / 2) if axis == 'y' else int((x1 + x2) / 2) for x1, y1, x2, y2 in lines]\n",
    "        coords = sorted(coords)\n",
    "        merged = []\n",
    "        current = coords[0]\n",
    "        for val in coords[1:]:\n",
    "            if abs(val - current) < threshold:\n",
    "                current = int((current + val) / 2)\n",
    "            else:\n",
    "                merged.append(current)\n",
    "                current = val\n",
    "        merged.append(current)\n",
    "        return merged\n",
    "\n",
    "    merged_horizontal = merge_line_coords(horizontal_lines, axis='y')\n",
    "    merged_vertical = merge_line_coords(vertical_lines, axis='x')\n",
    "\n",
    "    # Remove lines too close to image edges\n",
    "    merged_horizontal = [y for y in merged_horizontal if edge_threshold < y < (height - edge_threshold)]\n",
    "    merged_vertical = [x for x in merged_vertical if edge_threshold < x < (width - edge_threshold)]\n",
    "\n",
    "    if show_lines:\n",
    "        merged_image = image_rgb.copy()\n",
    "        for y in merged_horizontal:\n",
    "            cv2.line(merged_image, (0, y), (merged_image.shape[1], y), (255, 0, 0), 3)\n",
    "        for x in merged_vertical:\n",
    "            cv2.line(merged_image, (x, 0), (x, merged_image.shape[0]), (255, 0, 0), 3)\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(merged_image)\n",
    "        plt.title(\"Filtered Merged Grid Lines\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    return merged_horizontal, merged_vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_horse_template_matching(image_rgb, image_name=None):\n",
    "    img_rgb = image_rgb.copy()\n",
    "    height, width = img_rgb.shape[:2]\n",
    "    \n",
    "    best_match_val = -np.inf\n",
    "    best_match_loc = None\n",
    "    best_template_shape = None\n",
    "    best_template_index = None\n",
    "\n",
    "    for idx, template_rgb in enumerate(CORNER_HORSES_TEMPLATES):\n",
    "        if template_rgb is None:\n",
    "            print(f\"Template at index {idx} is None.\")\n",
    "            continue\n",
    "\n",
    "        h, w = template_rgb.shape[:2]\n",
    "        \n",
    "        # Template matching\n",
    "        res = cv2.matchTemplate(img_rgb, template_rgb, cv2.TM_CCOEFF_NORMED)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "        \n",
    "        if max_val > best_match_val:\n",
    "            best_match_val = max_val\n",
    "            best_match_loc = max_loc\n",
    "            best_template_shape = (h, w)\n",
    "            best_template_index = idx\n",
    "\n",
    "    print(f\"Best match index: {best_template_index} with score {best_match_val:.2f}\")\n",
    "    if best_match_val >= 0.65:\n",
    "        top_left = best_match_loc\n",
    "        h, w = best_template_shape\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "\n",
    "        # Draw match rectangle\n",
    "        cv2.rectangle(img_rgb, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "        # Center of match\n",
    "        center_x = top_left[0] + w // 2\n",
    "        center_y = top_left[1] + h // 2\n",
    "\n",
    "        # Determine closest corner\n",
    "        corners = [\n",
    "            (\"top-left\", (0, 0)),\n",
    "            (\"top-right\", (width, 0)),\n",
    "            (\"bottom-left\", (0, height)),\n",
    "            (\"bottom-right\", (width, height))\n",
    "        ]\n",
    "        \n",
    "        closest_corner = min(corners, key=lambda c: \n",
    "            np.sqrt((center_x - c[1][0])**2 + (center_y - c[1][1])**2))\n",
    "\n",
    "        # Print image name and closest corner\n",
    "        if image_name:\n",
    "            print(f\"{image_name}: {closest_corner[0]}\")\n",
    "        else:\n",
    "            print(f\"Closest corner: {closest_corner[0]}\")\n",
    "            \n",
    "        return closest_corner[0]\n",
    "    else:\n",
    "        if image_name:\n",
    "            print(f\"{image_name}: No good match found.\")\n",
    "        else:\n",
    "            print(\"No good match found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = './chessboard_outputs/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process all images in the images folder\n",
    "image_files = [os.path.join(BASE_IMG_FOLDER, f) for f in os.listdir(BASE_IMG_FOLDER) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# # Define specific image files to process\n",
    "# image_filenames_failed = [\n",
    "#     \"G006_IMG119.jpg\",\n",
    "#     \"G091_IMG053.jpg\",\n",
    "# ]\n",
    "\n",
    "# # Create full paths for each image file\n",
    "# image_files = [os.path.join(BASE_IMG_FOLDER, filename) for filename in image_filenames_failed]\n",
    "\n",
    "# Process each image\n",
    "failed_images = []\n",
    "rotations = {\n",
    "    \"top-left\": 90,\n",
    "    \"top-right\": 180,\n",
    "    \"bottom-left\": 0,\n",
    "    \"bottom-right\": -90\n",
    "}\n",
    "\n",
    "successful_images = {}\n",
    "\n",
    "for image_path in image_files:\n",
    "    filename = os.path.basename(image_path)\n",
    "    print(f\"Processing {filename}\")\n",
    "\n",
    "    if (SHOW_DEBUG_IMGS != \"NONE\"):\n",
    "        plt.figure(figsize=(16, 8))\n",
    "\n",
    "    warped, warped_original_rgb, matrix, ordered_corners, dst_corners = process_chessboard_image(image_path)\n",
    "\n",
    "    if warped is not None:\n",
    "        # Detect orientation\n",
    "        closest_corner = find_horse_template_matching(warped_original_rgb, filename)\n",
    "        rotation_angle = rotations.get(closest_corner, 0)\n",
    "\n",
    "        # Apply rotation to both warped images\n",
    "        def rotate_image(image, angle):\n",
    "            (h, w) = image.shape[:2]\n",
    "            center = (w // 2, h // 2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            return cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "        warped_rotated = rotate_image(warped, rotation_angle)\n",
    "        warped_original_rgb_rotated = rotate_image(warped_original_rgb, rotation_angle)\n",
    "\n",
    "        successful_images[filename] = {\n",
    "            'warped': warped_rotated,\n",
    "            'warped_original_rgb': warped_original_rgb_rotated,\n",
    "            'matrix': matrix,\n",
    "            'ordered_corners': ordered_corners,\n",
    "            'dst_corners': dst_corners\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        failed_images.append(filename)\n",
    "\n",
    "    if (SHOW_DEBUG_IMGS != \"NONE\"):\n",
    "        plt.tight_layout(pad=3.0)\n",
    "        subplot_path = os.path.join(output_dir, f\"subplots_{filename.split('.')[0]}.png\")\n",
    "        if SAVE_DEBUG_IMGS:\n",
    "            plt.savefig(subplot_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved subplots to {subplot_path}\")\n",
    "        plt.show()\n",
    "\n",
    "# Summary\n",
    "print(\"\\nImages where chessboard detection failed:\")\n",
    "for failed_image in failed_images:\n",
    "    print(failed_image)\n",
    "\n",
    "print(f\"\\nSuccessfully processed {len(image_files) - len(failed_images)}/{len(image_files)} images\")\n",
    "print(f\"Subplot images saved to: {os.path.abspath(output_dir)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "\n",
    "for k, v in successful_images.items():\n",
    "    board_size = v['warped_original_rgb'].shape[0]\n",
    "    crop_margin = int(board_size * 0.07)\n",
    "\n",
    "    cropped_board = v['warped_original_rgb'][crop_margin:board_size - crop_margin,\n",
    "                                             crop_margin:board_size - crop_margin]\n",
    "    v['cropped_board'] = cropped_board\n",
    "    h_lines, v_lines = detect_grid_lines(cropped_board, show_lines=False)\n",
    "\n",
    "    if len(h_lines) != 7 or len(v_lines) != 7:\n",
    "        print(f\"Not enough grid lines detected in {k}.\")\n",
    "        continue\n",
    "\n",
    "    height, width = cropped_board.shape[:2]\n",
    "    h_lines_full = [0] + sorted(h_lines) + [height]\n",
    "    v_lines_full = [0] + sorted(v_lines) + [width]\n",
    "\n",
    "    squares = []\n",
    "\n",
    "    for i in range(8):  # rows (0 = top = rank 8)\n",
    "        for j in range(8):  # columns (0 = left = file a)\n",
    "            y1, y2 = h_lines_full[i], h_lines_full[i + 1]\n",
    "            x1, x2 = v_lines_full[j], v_lines_full[j + 1]\n",
    "            square = cropped_board[y1:y2, x1:x2]\n",
    "            rank = 8 - i\n",
    "            file = files[j]\n",
    "            label = f\"{file}{rank}\"\n",
    "            squares.append({\n",
    "                \"position\": (i, j),\n",
    "                \"label\": label,\n",
    "                \"image\": square\n",
    "            })\n",
    "\n",
    "    v['squares'] = squares\n",
    "\n",
    "    # # Mostrar imagem original + imagem recortada lado a lado\n",
    "    # fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    # axes[0].imshow(v['warped_original_rgb'])\n",
    "    # axes[0].set_title(\"Original Warped Image\")\n",
    "    # axes[0].axis(\"off\")\n",
    "\n",
    "    # axes[1].imshow(cropped_board)\n",
    "    # axes[1].set_title(\"Cropped Board\")\n",
    "    # axes[1].axis(\"off\")\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    # # Mostrar as 64 casas com labels tipo \"e4\"\n",
    "    # fig, axs = plt.subplots(8, 8, figsize=(10, 10))\n",
    "    # fig.suptitle(f\"{k} â€” 64 Squares with Coordinates\", fontsize=16)\n",
    "    # for square in squares:\n",
    "    #     i, j = square['position']\n",
    "    #     axs[i, j].imshow(square['image'])\n",
    "    #     axs[i, j].text(3, 12, square['label'], fontsize=8, color='white',\n",
    "    #                    bbox=dict(facecolor='black', alpha=0.6, edgecolor='none', boxstyle='round,pad=0.1'))\n",
    "    #     axs[i, j].axis('off')\n",
    "    # plt.tight_layout()\n",
    "    # plt.subplots_adjust(top=0.93)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def create_combined_board_image(squares, square_size=(100, 100)):\n",
    "    \"\"\"Create a combined board image from the list of squares.\"\"\"\n",
    "    square_height, square_width = square_size\n",
    "    board_image = np.zeros((square_height * 8, square_width * 8, 3), dtype=np.uint8)\n",
    "\n",
    "    for square in squares:\n",
    "        i, j = square['position']\n",
    "        y1, y2 = i * square_height, (i + 1) * square_height\n",
    "        x1, x2 = j * square_width, (j + 1) * square_width\n",
    "\n",
    "        resized_square = cv2.resize(square['image'], (square_width, square_height))\n",
    "        board_image[y1:y2, x1:x2] = resized_square\n",
    "\n",
    "    return board_image\n",
    "\n",
    "\n",
    "def highlight_selected_squares(board_image, selected_squares, square_size):\n",
    "    \"\"\"Highlight the selected squares with a green border.\"\"\"\n",
    "    annotated = board_image.copy()\n",
    "    for (i, j) in selected_squares:\n",
    "        y1, y2 = i * square_size, (i + 1) * square_size\n",
    "        x1, x2 = j * square_size, (j + 1) * square_size\n",
    "        cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    return annotated\n",
    "\n",
    "\n",
    "def save_labeled_squares(squares, selected_squares, output_dir, image_name, square_size=(100, 100)):\n",
    "    \"\"\"Save images of labeled squares.\"\"\"\n",
    "    # Create directories for 0 and 1 labels if they don't exist\n",
    "    label_dirs = ['0', '1']\n",
    "    for label in label_dirs:\n",
    "        label_path = os.path.join(output_dir, label)\n",
    "        if not os.path.exists(label_path):\n",
    "            os.makedirs(label_path)\n",
    "\n",
    "    for square in squares:\n",
    "        i, j = square['position']\n",
    "        square_position = f\"{chr(97 + j)}{8 - i}\"  # Convert to chess notation (e.g., 'e4')\n",
    "        \n",
    "        # Extract the square image from the board (resize to square_size)\n",
    "        y1, y2 = i * square_size[0], (i + 1) * square_size[0]\n",
    "        x1, x2 = j * square_size[1], (j + 1) * square_size[1]\n",
    "        square_image = cv2.resize(square['image'], (square_size[1], square_size[0]))\n",
    "\n",
    "        # Determine label based on whether the square is selected\n",
    "        label = '1' if (i, j) in selected_squares else '0'\n",
    "\n",
    "        # Construct the file path\n",
    "        file_name = f\"{os.path.splitext(image_name)[0]}_{square_position}.jpg\"  # e.g., 'G000_IMG062_e4.jpg'\n",
    "        file_path = os.path.join(output_dir, label, file_name)\n",
    "\n",
    "        # Save the square image\n",
    "        cv2.imwrite(file_path, square_image)\n",
    "        print(f\"Saved: {file_path}\")\n",
    "\n",
    "\n",
    "def label_squares_interactively(squares, image_name, output_dir, window_name=\"Chessboard Labeling\", square_size=(100, 100)):\n",
    "    \"\"\"Allow the user to interactively select squares and label them, then save the results.\"\"\"\n",
    "    board_image = create_combined_board_image(squares, square_size)\n",
    "    selected_squares = set()\n",
    "\n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        nonlocal selected_squares\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            j = x // square_size[1]\n",
    "            i = y // square_size[0]\n",
    "            if (i, j) in selected_squares:\n",
    "                selected_squares.remove((i, j))\n",
    "            else:\n",
    "                selected_squares.add((i, j))\n",
    "            updated_img = highlight_selected_squares(board_image, selected_squares, square_size[0])\n",
    "            cv2.imshow(window_name, updated_img)\n",
    "\n",
    "    cv2.namedWindow(window_name)\n",
    "    cv2.setMouseCallback(window_name, mouse_callback)\n",
    "\n",
    "    cv2.imshow(window_name, board_image)\n",
    "    print(\"Click on squares to mark/unmark them. Press ESC to exit.\")\n",
    "    while True:\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27:  # ESC key to exit\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the labeled squares\n",
    "    save_labeled_squares(squares, selected_squares, output_dir, image_name, square_size)\n",
    "    return selected_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in successful_images.items():\n",
    "    if 'squares' not in v:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nLabeling squares for image: {k}\")\n",
    "    \n",
    "    # Use the image name and output directory for labeling\n",
    "    image_name = k  # The key `k` is the image name\n",
    "    output_dir = \"labeled_squares\"  # Directory where labeled images will be saved\n",
    "\n",
    "    # Call the labeling function and get the selected squares\n",
    "    selected = label_squares_interactively(v['squares'], image_name=image_name, output_dir=output_dir, square_size=(100, 100))\n",
    "\n",
    "    # Display the selected squares with labels\n",
    "    print(f\"Selected squares for {k}: {[v['squares'][i * 8 + j]['label'] for (i, j) in selected]}\")\n",
    "\n",
    "    # Store the selected squares in the dictionary for later use\n",
    "    v['selected_squares'] = selected\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
