{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for tunning\n",
    "\n",
    "BASE_IMG_FOLDER = './VC_2425_Project_public/images/'\n",
    "SHOW_DEBUG_IMGS = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def show_original_and_gray(image_path):\n",
    "    original_img = cv2.imread(image_path)\n",
    "    rgb_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "    gray_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if (SHOW_DEBUG_IMGS):\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(rgb_img)\n",
    "        plt.axis('off')\n",
    "        plt.title('Original RGB Image')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(gray_img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title('Grayscale Image')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return original_img, gray_img"
=======
    "def preprocess_image(gray_img, blur_kernel_size=11, intensity_factor=1.5, laplacian_kernel_size=3):\n",
    "    blurred = cv2.GaussianBlur(gray_img, (blur_kernel_size, blur_kernel_size), 0)\n",
    "    adjusted_img = cv2.convertScaleAbs(blurred, alpha=intensity_factor, beta=0)\n",
    "\n",
    "    # Morphological opening to remove small details like pieces\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    opened = cv2.morphologyEx(adjusted_img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    laplacian = cv2.Laplacian(opened, cv2.CV_64F, ksize=laplacian_kernel_size)\n",
    "    laplacian = cv2.convertScaleAbs(laplacian)\n",
    "\n",
    "    # OTSU + optional manual offset to suppress weak edges\n",
    "    otsu_thresh_val, _ = cv2.threshold(laplacian, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    _, binary_img = cv2.threshold(laplacian, otsu_thresh_val + 20, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # plt.figure(figsize=(7, 7))\n",
    "    # plt.title(\"Binary after Opening + Laplacian + OTSU + Offset\")\n",
    "    # plt.imshow(binary_img, cmap=\"gray\")\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    return binary_img"
>>>>>>> 7f74f5ac539e4245cafbcb0bf69e8f3bcc557c46
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def preprocess_image(gray_img, blur_kernel_size=11, intensity_factor=1.5, laplacian_kernel_size=3):\n",
    "    blurred = cv2.GaussianBlur(gray_img, (blur_kernel_size, blur_kernel_size), 0)\n",
    "    adjusted_img = cv2.convertScaleAbs(blurred, alpha=intensity_factor, beta=0)\n",
    "\n",
    "    # Morphological opening to remove small details like pieces\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    opened = cv2.morphologyEx(adjusted_img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    laplacian = cv2.Laplacian(opened, cv2.CV_64F, ksize=laplacian_kernel_size)\n",
    "    laplacian = cv2.convertScaleAbs(laplacian)\n",
    "\n",
    "    # OTSU + optional manual offset to suppress weak edges\n",
    "    otsu_thresh_val, _ = cv2.threshold(laplacian, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    _, binary_img = cv2.threshold(laplacian, otsu_thresh_val + 20, 255, cv2.THRESH_BINARY)\n",
=======
    "def detect_lines(binary_img, min_line_length=50, max_line_gap=50):\n",
    "    # Canny edge detection with lower threshold\n",
    "    canny_image = cv2.Canny(binary_img, 50, 200)  # Tuning thresholds to capture better edges\n",
    "\n",
    "    # Use dilation to reinforce edges\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    dilation_image = cv2.dilate(canny_image, kernel, iterations=1)\n",
    "    \n",
    "    \n",
    "    # plt.figure(figsize=(15, 5))\n",
    "    # plt.title(\"Dilated Edges\")\n",
    "    # plt.imshow(dilation_image, cmap=\"gray\")\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    \n",
    "    \n",
    "    # Hough Lines transform for line detection\n",
    "    lines = cv2.HoughLinesP(dilation_image, 1, np.pi / 180, threshold=500, \n",
    "                            minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "\n",
    "    # Create an image to store the detected lines\n",
    "    black_image = np.zeros_like(dilation_image)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(black_image, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "\n",
    "    # Apply final dilation to reinforce the lines detected\n",
    "    final_kernel = np.ones((3, 3), np.uint8)\n",
    "    black_image = cv2.dilate(black_image, final_kernel, iterations=1)\n",
    "\n",
    "    \n",
    "\n",
>>>>>>> 7f74f5ac539e4245cafbcb0bf69e8f3bcc557c46
    "\n",
    "    if (SHOW_DEBUG_IMGS):\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        plt.title(\"Binary after Opening + Laplacian + OTSU + Offset\")\n",
    "        plt.imshow(binary_img, cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return binary_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def detect_lines(binary_img, min_line_length=50, max_line_gap=50):\n",
    "    # Canny edge detection with lower threshold\n",
    "    canny_image = cv2.Canny(binary_img, 50, 200)  # Tuning thresholds to capture better edges\n",
    "\n",
    "    # Use dilation to reinforce edges\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    dilation_image = cv2.dilate(canny_image, kernel, iterations=1)\n",
    "    \n",
    "    if (SHOW_DEBUG_IMGS):\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.title(\"Dilated Edges\")\n",
    "        plt.imshow(dilation_image, cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # Hough Lines transform for line detection\n",
    "    lines = cv2.HoughLinesP(dilation_image, 1, np.pi / 180, threshold=500, \n",
    "                            minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "\n",
    "    # Create an image to store the detected lines\n",
    "    black_image = np.zeros_like(dilation_image)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(black_image, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "\n",
    "    # Apply final dilation to reinforce the lines detected\n",
    "    final_kernel = np.ones((3, 3), np.uint8)\n",
    "    black_image = cv2.dilate(black_image, final_kernel, iterations=1)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return black_image"
=======
    "def remove_noise_components(line_img, min_area=1000, keep_largest=True):\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(line_img, connectivity=8)\n",
    "    \n",
    "    # Create a black image to store the final result\n",
    "    final_image = np.zeros_like(line_img)\n",
    "    \n",
    "    if keep_largest:\n",
    "        # Get the areas of all components (ignoring the background)\n",
    "        areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "        \n",
    "        # Find the label of the largest component\n",
    "        max_label = 1 + np.argmax(areas)\n",
    "        \n",
    "        # Keep only the largest component\n",
    "        final_image[labels == max_label] = 255\n",
    "    else:\n",
    "        # If not keeping only the largest component, keep components above the min_area threshold\n",
    "        for label in range(1, num_labels):\n",
    "            area = stats[label, cv2.CC_STAT_AREA]\n",
    "            if area >= min_area:\n",
    "                final_image[labels == label] = 255\n",
    "\n",
    "    # # Optional: Show the result for debugging\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.title(\"Only Board Lines (Filtered)\")\n",
    "    # plt.imshow(final_image, cmap=\"gray\")\n",
    "    # plt.axis('off')\n",
    "\n",
    "    return final_image\n"
>>>>>>> 7f74f5ac539e4245cafbcb0bf69e8f3bcc557c46
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise_components(line_img, min_area=1000, keep_largest=True):\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(line_img, connectivity=8)\n",
    "    \n",
    "    # Create a black image to store the final result\n",
    "    final_image = np.zeros_like(line_img)\n",
    "    \n",
    "    if keep_largest:\n",
    "        # Get the areas of all components (ignoring the background)\n",
    "        areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "        \n",
    "        # Find the label of the largest component\n",
    "        max_label = 1 + np.argmax(areas)\n",
    "        \n",
    "        # Keep only the largest component\n",
    "        final_image[labels == max_label] = 255\n",
    "    else:\n",
    "        # If not keeping only the largest component, keep components above the min_area threshold\n",
    "        for label in range(1, num_labels):\n",
    "            area = stats[label, cv2.CC_STAT_AREA]\n",
    "            if area >= min_area:\n",
    "                final_image[labels == label] = 255\n",
    "\n",
    "    if (SHOW_DEBUG_IMGS):\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"Only Board Lines (Filtered)\")\n",
    "        plt.imshow(final_image, cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    return final_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chessboard_contour(line_img):\n",
    "    contours, _ = cv2.findContours(line_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    if contours:\n",
    "        return contours[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_corners(corners):\n",
    "    sorted_by_y = sorted(corners, key=lambda p: p[1])\n",
    "    top_two = sorted(sorted_by_y[:2], key=lambda p: p[0])\n",
    "    bottom_two = sorted(sorted_by_y[2:], key=lambda p: p[0])\n",
    "    return np.array([top_two[0], top_two[1], bottom_two[0], bottom_two[1]], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_chessboard(gray_img, contour, board_size=800):\n",
    "    epsilon = 0.05 * cv2.arcLength(contour, True)\n",
    "    approx_corners = cv2.approxPolyDP(contour, epsilon, True)\n",
    "    if len(approx_corners) == 4:\n",
    "        corners = np.squeeze(approx_corners)\n",
    "        ordered_corners = order_corners(corners)\n",
    "        dst_corners = np.array([\n",
    "            [0, 0], [board_size - 1, 0],\n",
    "            [0, board_size - 1], [board_size - 1, board_size - 1]\n",
    "        ], dtype=\"float32\")\n",
    "        matrix = cv2.getPerspectiveTransform(ordered_corners, dst_corners)\n",
    "        warped_board = cv2.warpPerspective(gray_img, matrix, (board_size, board_size))\n",
    "\n",
<<<<<<< HEAD
    "        if (SHOW_DEBUG_IMGS):\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.title(\"Warped Chessboard\")\n",
    "            plt.imshow(warped_board, cmap=\"gray\")\n",
    "            plt.axis('off')\n",
=======
    "        # plt.subplot(1, 2, 2)\n",
    "        # plt.title(\"Warped Chessboard\")\n",
    "        # plt.imshow(warped_board, cmap=\"gray\")\n",
    "        # plt.axis('off')\n",
>>>>>>> 7f74f5ac539e4245cafbcb0bf69e8f3bcc557c46
    "\n",
    "        return warped_board\n",
    "    else:\n",
    "        print(\"Error: Did not find exactly 4 corners!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chessboard_image(image_path):\n",
    "    original_img, gray_img = show_original_and_gray(image_path)\n",
    "    otsu_binary = preprocess_image(gray_img)\n",
    "    line_img = detect_lines(otsu_binary)\n",
    "    clean_line_img = remove_noise_components(line_img)\n",
    "    contour = find_chessboard_contour(clean_line_img)\n",
    "    if contour is not None:\n",
    "        return warp_chessboard(gray_img, contour)\n",
    "    else:\n",
    "        print(\"Chessboard contour not found!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing G000_IMG062.jpg\n",
      "Processing G000_IMG087.jpg\n",
      "Processing G000_IMG102.jpg\n",
      "Processing G006_IMG048.jpg\n",
      "Processing G006_IMG086.jpg\n",
      "Processing G006_IMG119.jpg\n",
      "Error: Did not find exactly 4 corners!\n",
      "Processing G019_IMG082.jpg\n",
      "Processing G028_IMG015.jpg\n",
      "Processing G028_IMG062.jpg\n",
      "Processing G028_IMG098.jpg\n",
      "Processing G028_IMG101.jpg\n",
      "Processing G033_IMG043.jpg\n",
      "Processing G033_IMG075.jpg\n",
      "Processing G033_IMG088.jpg\n",
      "Processing G033_IMG101.jpg\n",
      "Processing G038_IMG074.jpg\n",
      "Processing G038_IMG088.jpg\n",
      "Processing G038_IMG103.jpg\n",
      "Processing G038_IMG105.jpg\n",
      "Processing G041_IMG042.jpg\n",
      "Processing G041_IMG048.jpg\n",
      "Processing G041_IMG088.jpg\n",
      "Error: Did not find exactly 4 corners!\n",
      "Processing G041_IMG098.jpg\n",
      "Processing G047_IMG053.jpg\n",
      "Processing G047_IMG068.jpg\n",
      "Processing G047_IMG102.jpg\n",
      "Processing G047_IMG107.jpg\n",
      "Processing G056_IMG017.jpg\n",
      "Processing G056_IMG077.jpg\n",
      "Processing G056_IMG097.jpg\n",
      "Processing G058_IMG044.jpg\n",
      "Processing G058_IMG074.jpg\n",
      "Processing G058_IMG100.jpg\n",
      "Processing G061_IMG080.jpg\n",
      "Processing G061_IMG092.jpg\n",
      "Processing G061_IMG098.jpg\n",
      "Processing G072_IMG083.jpg\n",
      "Processing G072_IMG098.jpg\n",
      "Processing G076_IMG072.jpg\n",
      "Processing G076_IMG089.jpg\n",
      "Processing G076_IMG095.jpg\n",
      "Processing G078_IMG092.jpg\n",
      "Processing G083_IMG073.jpg\n",
      "Processing G083_IMG089.jpg\n",
      "Processing G087_IMG093.jpg\n",
      "Processing G087_IMG099.jpg\n",
      "Processing G091_IMG053.jpg\n",
      "Processing G091_IMG074.jpg\n",
      "Processing G091_IMG102.jpg\n",
      "Processing G099_IMG094.jpg\n",
      "\n",
      "Images where chessboard detection failed:\n",
      "G006_IMG119.jpg\n",
      "G041_IMG088.jpg\n"
     ]
    }
   ],
>>>>>>> 7f74f5ac539e4245cafbcb0bf69e8f3bcc557c46
   "source": [
    "# Process all images in the images folder\n",
    "image_files = [os.path.join(BASE_IMG_FOLDER, f) for f in os.listdir(BASE_IMG_FOLDER) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# # Define specific image files to process\n",
    "# image_filenames_failed = [\n",
    "# \"G041_IMG088.jpg\",\n",
    "# \"G006_IMG119.jpg\"\n",
    "# ]\n",
    "\n",
    "# # Create full paths for each image file\n",
    "# image_files = [os.path.join(BASE_IMG_FOLDER, filename) for filename in image_filenames_failed]\n",
    "\n",
    "# # Define specific image files to process\n",
    "# image_filenames_failed = [\n",
    "# \"G041_IMG088.jpg\",\n",
    "# \"G006_IMG119.jpg\"\n",
    "# ]\n",
    "\n",
    "# # Create full paths for each image file\n",
    "# image_files = [os.path.join(images_folder, filename) for filename in image_filenames_failed]\n",
    "\n",
    "# Process each image\n",
    "failed_images = []\n",
    "for image_path in image_files:\n",
    "    print(f\"Processing {os.path.basename(image_path)}\")\n",
    "    warped = process_chessboard_image(image_path)\n",
<<<<<<< HEAD
    "    if (SHOW_DEBUG_IMGS):\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
=======
    "    # plt.figure(figsize=(15, 7))\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
>>>>>>> 7f74f5ac539e4245cafbcb0bf69e8f3bcc557c46
    "    \n",
    "    if warped is None:\n",
    "        failed_images.append(os.path.basename(image_path))\n",
    "\n",
    "print(\"\\nImages where chessboard detection failed:\")\n",
    "for failed_image in failed_images:\n",
    "    print(failed_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
